{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "### a.\n",
    "<br> $ F = \\{V, \\sum, R, S\\} $\n",
    "<br> V = \\{'S', 'P', 'V', 'A', 'N'\\} \n",
    "<br> $ \\sum = $ \\{'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', \n",
    "           'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'A', 'B', 'C', 'D', \n",
    "           'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', \n",
    "           'T', 'U', 'V', 'W', 'X', 'Y', 'Z' \\} \n",
    "<br> R = rules = \\{\n",
    "        'S' -> 'PVAN' <br>\n",
    "        'N' -> 'apple' | 'banana' | 'orange' | 'grapefruit' | 'coconut' | 'peach' | 'pear' | 'lychee' | 'rasberry' | 'watermelon' |<br>\n",
    "        'V' -> 'eat' | 'buy' | 'love' | 'cut' |'digest' | <br>\n",
    "        'A' -> 'big' | 'small' | 'sweet' | 'sour' | 'delicious' | <br>\n",
    "        'P' -> 'I' | 'he' | 'she' | 'they' | 'we' | 'you' | 'who' |<br>\n",
    "        \\} <br>\n",
    "S = \\{'S'\\}\n",
    "\n",
    "### b.\n",
    "\n",
    "The grammar above, F, describing the language of some simple english sentences revolving around fruit is unambiguous. Each string that can be generated only has one derivation, meaning we can't take two different \"routes\" to reach the same string. We know this because the starting rule, \"S->PVAN\" only derives P,V,A, and N in that exact order. Furthermore, P,V,A, and N only generate sets of terminals (words) that are unique in the rule structure. Thus, the grammar is unambiguous\n",
    "\n",
    "### c.\n",
    "\n",
    "Please refer to code cell below for formal definition of an equivalent NPDA. I will provide an informal definition here. We follow Sisper's method and proof that every CFG has an equivalent PDA. The code takes in a dictionary as a set of the rules for our CFG. It will iterate through, creating the transitions required for our PDA. The most important state is \"q0\" which is essentially a looping state. For each individual rule, there will be a loop here that replaces each variable, pushing the right-hand side of the rule onto the stack instead. There will also be another kind of loop that upon an input (terminal) matching the top of the stack, this character will be popped off the stack. Thus, the larger picture is each variable will continually be replaced by its right-hand-side rule until only terminals remain, then non-deterministically check if an input value also matches top of stack. If a string were to be generated by the grammar, the PDA will eventually become an empty stack, leading to accept state, accepting the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rules are strategically converted to a python dictionary with values being list\n",
    "# the properties of CFG rules closely resembles the immutability of this data structure\n",
    "# or at least is sufficient for our purposes\n",
    "rules_F = {\n",
    "    'S': ['P V A N'],\n",
    "    'N': ['apple', 'banana', 'orange', 'grapefruit', 'coconut', 'peach', 'pear', 'lychee', 'raspberry', 'watermelon'],\n",
    "    'V': ['eat', 'buy', 'love', 'cut', 'digest'],\n",
    "    'A': ['big', 'small', 'sweet', 'sour', 'delicious'],\n",
    "    'P': ['I', 'he', 'she', 'they', 'we', 'you', 'who']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce input characters and stack symbols\n",
    "def characters(rules):\n",
    "    variables = []\n",
    "    terminals = []\n",
    "    for var in rules:\n",
    "        variables.append(var)\n",
    "    for i in rules:\n",
    "        for j in rules[i]:\n",
    "            for k in j:\n",
    "                if k not in variables:\n",
    "                    terminals.append(k)\n",
    "    # unique values only\n",
    "    variables = list(set(variables))\n",
    "    terminals = list(set(terminals))\n",
    "    return variables, terminals\n",
    "\n",
    "# parses through a CFG dictionary, producing transitions for NPDA using Sisper's Lemma 2.21\n",
    "def cfg_to_npda_helper(grammar):\n",
    "    \n",
    "    # initialize transitions \n",
    "    transitions = {\n",
    "        'q_start': {\n",
    "            '': {\n",
    "                '$': {('q0', ('S', '$'))},\n",
    "            },\n",
    "            # this transition is for testing only. Input \"X\" should easily be accepted\n",
    "            'X': {'$':{('q_start', ('Z', '$'))}}\n",
    "        },\n",
    "        'q0': {\n",
    "            '': {\n",
    "                '$':{('q_accept', '')}\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "    # get variables and terminals from characters function defined above\n",
    "    variables, terminals = characters(grammar)\n",
    "    \n",
    "    # I won't explain all the code, but the idea is to loop through every rule in the dictionary\n",
    "    # A few patterns are observerd, for example for rules of length 1 etc. These are implemented\n",
    "    # for more efficient code. Otherwise, refer to Sisper Lemma 2.21 for details on what is happening\n",
    "    for variable in variables:\n",
    "        transitions['q0'][''][variable] = set()\n",
    "    for terminal in terminals:\n",
    "        transitions['q0'][terminal] = {terminal: {('q0', '')}}\n",
    "    counter = 0\n",
    "    state = 'q'+str(counter)\n",
    "    for var in grammar:\n",
    "        for rule in grammar[var]:\n",
    "            if len(rule) == 1:\n",
    "                # for rules such as O -> E or O -> b etc.\n",
    "                transitions['q0'][''][var].add(('q0', rule))\n",
    "            elif rule == '':\n",
    "                # for rules such as O -> '', empty string transitions\n",
    "                transitions['q0'][''][var].add(('q0', ''))\n",
    "            else:\n",
    "                counter += 1\n",
    "                state = 'q'+str(counter)\n",
    "                transitions['q0'][''][var].add((state, rule[-1]))\n",
    "                temp = -1\n",
    "                \n",
    "                # we want the add the characters of the rule in reverse, creating new state each time\n",
    "                # except for the first character, that will transition back to q0\n",
    "                for character in rule[::-1][:-2]:\n",
    "                    temp -= 1\n",
    "                    transitions[state] = {'':{character:{('q'+str(counter+1), (rule[temp], character))}}}\n",
    "                    counter += 1\n",
    "                    state = 'q'+str(counter)\n",
    "                transitions[state] = {'':{rule[1]:{('q0', (rule[0], rule[1]))}}}\n",
    "    # instead of re-writing it by hand later, use elegant power of code to get all states\n",
    "    states_set = set()\n",
    "    for i in transitions:\n",
    "        states_set.add(i)\n",
    "    states_set.add('q_accept')\n",
    "    return transitions, states_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_F, terminals_F = characters(rules_F)\n",
    "npda_F_transitions, states_F_set = cfg_to_npda_helper(rules_F)\n",
    "\n",
    "# Formal Definition of equivalent machine to cfg_F:\n",
    "#print('variables: ', variables_F)\n",
    "#print('terminals: ', terminals_F)\n",
    "#print('transitions: ', npda_F_transitions)\n",
    "#print('states: ', states_F_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from automata.pda.npda import NPDA\n",
    "\n",
    "def create_cfg_to_npda(variables, terminals, transitions, states):\n",
    "    npda = NPDA(\n",
    "        states=states,\n",
    "        # append a few extra characters, for testing, and initial stack symbol\n",
    "        input_symbols=set(terminals+['X']),\n",
    "        stack_symbols=set(variables+terminals+['$','X']),\n",
    "        transitions=transitions,\n",
    "        initial_state='q_start',\n",
    "        initial_stack_symbol='$', # initialize stack with \"$\"\n",
    "        final_states={'q_accept'},\n",
    "        # if recognizable string, NPDA should end both on the accept state, as well as with empty stack\n",
    "        acceptance_mode='both'\n",
    "    )\n",
    "    return npda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1.d)\n",
    "npda_F = create_cfg_to_npda(variables_F, terminals_F, npda_F_transitions, states_F_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comprehensive tests for npda_F, noting when npda should and should not accept\n",
    "# would be nice one day to make this more grammatically sound. \"He eat\" kills me inside\n",
    "assert(npda_F.accepts_input('I eat sweet apple') == True)\n",
    "assert(npda_F.accepts_input('you cut small raspberry') == True)\n",
    "assert(npda_F.accepts_input('he love delicious peach') == True)\n",
    "assert(npda_F.accepts_input('I cut big cabbage') == False)\n",
    "assert(npda_F.accepts_input('Chretien eat sweet apple') == False)\n",
    "assert(npda_F.accepts_input('I eat sweet Apple') == False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "### a.\n",
    "\n",
    "We can build our translation automaton through a Mealy machine with no accept state. A Mealy Machine functions closely to a Finite State Automaton. However, upon input, the mealy machine will instead print or return an output. Our autmaton will work as so. q0 will transition with all inputs from P. The translation is printed if the transition is made. The next layer, all receiving nodes from inputs in P, will transition with all inputs from V; again, if an input matches a possible transition, make the transition and print translation. We repeat this for a third and fourth layer of nodes for all words in A and N. In all, we will have (P$\\times$V$\\times$A$\\times$N)+1 total number of nodes.\n",
    "\n",
    "Output translations as so: \n",
    "\n",
    "\\{\n",
    "'apple' -> 'apfel'\n",
    "'orange' -> 'orange'\n",
    "'grapefruit' -> 'grapefruit'\n",
    "'coconut' -> 'kokosnuss'\n",
    "'peach' -> 'pfirsich'\n",
    "'pear' -> 'birne'\n",
    "'lychee' -> 'litschi'\n",
    "'rasberry' -> 'himbeere'\n",
    "'watermelon' -> 'wassermelone'\n",
    "'eat' -> 'essen'\n",
    "'buy' -> 'kaufen'\n",
    "'love' -> 'liebe'\n",
    "'cut' -> 'schneiden'\n",
    "'digest' -> 'verdauen'\n",
    "'big' -> 'gro&szling;'\n",
    "'small' -> 'klein'\n",
    "'sweet' -> 's&uuml;ss'\n",
    "'sour' -> 'sauer'\n",
    "'delicious' -> 'lecker'\n",
    "'I' -> 'ich'\n",
    "'he' -> 'er'\n",
    "'she' -> 'sie'\n",
    "'they' -> 'sie'\n",
    "'we' -> 'wir'\n",
    "'you' -> 'sie'\n",
    "'who' -> 'wer'\n",
    "\\}\n",
    "$M = \\{S, S_0, \\Sigma, \\Lambda, T, G \\} $\n",
    "\n",
    "$S = \\{q_0, q_1, q_2, ... , q_n |$ where $n= |P\\times V\\times A\\times N|+1 $ \\}\n",
    "\n",
    "$S_0 = \\{q_0\\}$\n",
    "\n",
    "$\\Sigma$ = \\{'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z'\\}\n",
    "\n",
    "$\\Lambda$ = \\{'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '&auml;', '&ouml;', '&uuml;', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',  '&Auml;', '&Ouml;', '&Uuml;', '&szlig;'\\}\n",
    "\n",
    "$T = \\{S\\times \\sigma \\rightarrow S |$ as described above \\}\n",
    "\n",
    "$G = \\{S\\times \\lambda \\rightarrow S |$ direct translations as shown above \\}\n",
    "\n",
    "### b.\n",
    "\n",
    "The main computational drawback to the approach above is its how many states it will. If we were to build a sentence, of say 20 words, with 8 parts of speech, 100 words in each POS, our automata will have 100^20 states! And when we factor in realistically how grammar works, for example following a verb can be both proper nouns or objective pronouns, then this number becomes even more massive! This is obviously highly inefficient, we're going word by word so we never know what is going to come next, and have to make sure that following each word, there is a transition to all the possible words that can come after it. Furthermore, there is no context of a word being taken in account. If we have a word, talk, it can either be \"I talk\" or \"He talks.\" These grammatical cues and differences, tenses etc. are unaccounted for, and arguably if you translate word-by-word, impossible to account for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "### a. \n",
    "<br> $ G = \\{V, \\sum, R, S\\} $\n",
    "<br> V = \\{'S', 'I', 'E', 'O', 'F', 'V', 'D', 'M', 'C', 'U', 'N'\\} \n",
    "<br> $ \\sum = $ \\{'f', '(', 'x', ')', '=', 'x', ',', 'y', ')', '=', '(', ')', '(', ')', '+', '-', '*', '/', '^', 's', 'i', 'n', '(', ')', 'c', 'o', 's', '(', ')', 't', 'a', 'n', '(', ')', 's', 'q', 'r', 't', '(', ')', 'l', 'o', 'g', '(', ')', 'x', '(', ')', '(', ')', '+', '-', '*', '/', 's', 'i', 'n', '(', ')', 'c', 'o', 's', '(', ')', 't', 'a', 'n', '(', ')', 's', 'q', 'r', 't', '(', ')', 'l', 'o', 'g', '(', ')', 'x', 'y', '1', '2', '3', '4', '5', '6', '7', '8', '9', '0'\\} \n",
    "<br> R = rules = \\{\n",
    "        'S' -> 'f(I' <br>\n",
    "        'I' -> 'x)=E' | 'x,y)=D' |<br>\n",
    "        'E' -> 'EO' | '(EO)' | '(E)O' | 'F' |'V' | <br>\n",
    "        'O' -> '+E' | '-E' | '\\*E' | '/E' | '^E' | $ \\epsilon\\ $ <br>\n",
    "        'F' -> 'sin(E)' | 'cos(E)' | 'tan(E)' | 'sqrt(E)' | 'log(E)'<br>\n",
    "        'V' -> 'NV' | 'N' | 'x' |<br>\n",
    "        'D' -> 'DM' | '(DM)' | '(D)M' | 'C' |'U' <br>\n",
    "        'M' -> '+D' | '-D' | '\\*D' | '/D' | $ \\epsilon\\ $ <br>\n",
    "        'C' -> 'sin(D)' | 'cos(D)' | 'tan(D)' | 'sqrt(D)' | 'log(D)' <br>\n",
    "        'U' -> 'NU' | 'N' | 'x' | 'y' |<br>\n",
    "        'N' -> '1' |'2' |'3' |'4' |'5' |'6' |'7' |'8' |'9' |'0'<br>\n",
    "        \\} <br>\n",
    "S = \\{'S'\\}\n",
    "\n",
    "### b.\n",
    "For the formal description of the equivalent machine to the context-free grammar above, which is a non-deterministic pushdown automata, please refer to the NPDA below, \"npda_function_generator.\" I will provide a brief overview here for an informal description. The context-free language recognized by the grammar above is every string of the sort \"f(x)=E\" or \"f(x,y)=D,\" with E and D being any expression generatable by natural numbers, basic operators (+,-,$\\times$, $\\div$, $\\exp$) and functions: $\\sin$, $\\cos$, $\\tan$, $ \\sqrt{} $, and $\\log$ . The difference being that single input x is valid for E and two inputs, x and y, are valid for D. We start by converting the grammar above, G, to the proper corresponding NPDA according to Sisper Lemma 2.21. We already know that every CFG has an equivalent PDA, so this should be possible. Once we get the transitions, we can simply utilize automata.lib to implement the final steps of our getting our NPDA simulator.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accepted functions: sin, cos, tan, sqrt, log\n",
    "# Accepted operators: +, -, /, *, ^\n",
    "rules_G = {'S': ['f(I'],\n",
    "        'I': ['x)=E', 'x,y)=D'],\n",
    "        'E': ['EO', '(EO)', '(E)O', 'F','V'],\n",
    "        'O': ['+E', '-E', '*E', '/E', '^E', ''],\n",
    "        'F': ['sin(E)', 'cos(E)', 'tan(E)', 'sqrt(E)', 'log(E)'],\n",
    "        'V': ['NV', 'N', 'x'],\n",
    "        'D': ['DM', '(DM)', '(D)M', 'C','U'],\n",
    "        'M': ['+D', '-D', '*D', '/D', ''],\n",
    "        'C': ['sin(D)', 'cos(D)', 'tan(D)', 'sqrt(D)', 'log(D)'],\n",
    "        'U': ['NU', 'N', 'x', 'y'],\n",
    "        'N': ['1','2','3','4','5','6','7','8','9','0']\n",
    "        }\n",
    "\n",
    "# I should say chomsky-esque. I tried my best but it gets so large, can't process in npda\n",
    "rules_G_chomsky = {\n",
    "        'S': ['f(I'],\n",
    "        'I': ['x)=E', 'x,y)=D'],\n",
    "        'E': ['xO', '(xO)', '(x)O', '(x)', 'sin(x)', 'cos(x)', 'tan(x)', 'sqrt(x)', 'log(x)', 'EO', '(EO)', '(E)O', '(E)', 'sin(E)', 'cos(E)', 'tan(E)', 'sqrt(E)', 'log(E)', 'EV'],\n",
    "        'V': ['1','2','3','4','5','6','7','8','9','0'],\n",
    "        'O': ['BE'],\n",
    "        'B': ['+', '-', '*', '/', '^'],\n",
    "        'D': ['YM', '(YM)', '(Y)M', '(Y)', 'sin(Y)', 'cos(Y)', 'tan(Y)', 'sqrt(Y)', 'log(Y)', 'DM', '(DM)', '(D)M', '(D)', 'sin(D)', 'cos(D)', 'tan(D)', 'sqrt(D)', 'log(D)', 'DV'],\n",
    "        'M': ['CD'],\n",
    "        'C': ['+', '-', '*', '/', '^'],\n",
    "        'Y': ['x', 'y']\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_G, terminals_G = characters(rules_G)\n",
    "npda_G_transitions, states_G_set = cfg_to_npda_helper(rules_G)\n",
    "\n",
    "# Formal Definition of equivalent machine to cfg_G:\n",
    "#print('variables: ', variables_G)\n",
    "#print('terminals: ', terminals_G)\n",
    "#print('transitions: ', npda_G_transitions)\n",
    "#print('states: ', states_G_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "npda_G = create_cfg_to_npda(variables_G, terminals_G, npda_G_transitions, states_G_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(npda_G.validate() == True)\n",
    "assert(npda_G.accepts_input('f(x)=8+8+10*x'))\n",
    "assert(npda_G.accepts_input('f(x,y)=(sin(x)+tan(x/y))*x') == True)\n",
    "assert(npda_G.accepts_input('f(x)=x+x+x') == True)\n",
    "assert(npda_G.accepts_input('f(x,y,z)=1+2+3') == False)\n",
    "# the more nested functions there are the longer the runtime. Should be right though\n",
    "#print(list(npda_function_generator.read_input_stepwise('f(x)=sin(tan(log(cos(5*x^100))))')))\n",
    "#print(npda_function_generator.read_input('f(x,y)=2+2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d.\n",
    "\n",
    "We will use python's eval() function to help parse our string and generate appropriate function. No need to reinvent the wheel here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sin, cos, tan, log10, sqrt, pi\n",
    "\n",
    "# function that outputs function generated from our input string, if recognized by NPDA\n",
    "def output_function(npda, input_string):\n",
    "    if npda.accepts_input(input_string):\n",
    "        \n",
    "        #parse our string, if accepted, return function that evaluates left hand side\n",
    "        parse = input_string.find('=')\n",
    "        parse_string = input_string[parse+1:]\n",
    "        \n",
    "        # '^' is in our language but python evaluates '**' instead\n",
    "        parse_string = parse_string.replace('^', '**').replace('log', 'log10')\n",
    "        \n",
    "        # default values so x and y are optional. Our npda will reject if x,y appear in f(x) function\n",
    "        def evaluate(x=1, y=1):\n",
    "            x = x\n",
    "            y = y\n",
    "            z = eval(parse_string)\n",
    "            return z\n",
    "        return evaluate\n",
    "    else:\n",
    "        return 'Input string invalid'\n",
    "# tests\n",
    "function1 = output_function(npda_G, 'f(x,y)=(sin(x)+cos(y))*5+10')   \n",
    "function2 = output_function(npda_G, 'f(x)=10*x+log(10^x)')     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure function generator works\n",
    "assert(function1(x=0, y=0) == 15.0)\n",
    "assert(function2(x=5) == 55.0)\n",
    "assert((function2(x=2) == 30) == False)\n",
    "assert((function2(x=2) == 22) == True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'q_start': {'': {'$': {('q0', ('S', '$'))}}, 'X': {'$': {('q_start', ('Z', '$'))}}}, 'q0': {'': {'$': {('q_accept', '')}, 'T': {('q0', ''), ('q3', 'a')}, 'S': {('q0', 'b'), ('q1', 'b')}}, 'a': {'a': {('q0', '')}}, 'b': {'b': {('q0', '')}}}, 'q1': {'': {'b': {('q2', ('T', 'b'))}}}, 'q2': {'': {'T': {('q0', ('a', 'T'))}}}, 'q3': {'': {'a': {('q0', ('T', 'a'))}}}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{PDAConfiguration('q0', 'Xa', PDAStack('$', 'b')),\n",
       " PDAConfiguration('q1', 'Xa', PDAStack('$', 'b')),\n",
       " PDAConfiguration('q_accept', '', PDAStack('$',)),\n",
       " PDAConfiguration('q_accept', 'Xa', PDAStack('$',))}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A test NPDA to help simplify and debug syntaxical errors. Otherwise ignore\n",
    "from automata.pda.npda import NPDA\n",
    "test_g = {'S':['aTb', 'b'],\n",
    "          'T':['Ta', '']\n",
    "    }\n",
    "npda_transitions_test, states_set_test = cfg_to_npda(test_g)\n",
    "print(npda_transitions_test)\n",
    "states_set_test.add('q_accept')\n",
    "variables_test, terminals_test = characters(test_g)\n",
    "test_g_npda = NPDA(\n",
    "    states=states_set_test,\n",
    "    input_symbols=set(variables_test+terminals_test+['X', 'Z']),\n",
    "    stack_symbols=set(variables_test+terminals_test+['X', '$', 'Z']),\n",
    "    transitions={\n",
    "        'q_start': {\n",
    "            '': {'$': {('q0', ('S', '$'))}}, \n",
    "            'X': {'$': {('q0', ('b', '$'))}}\n",
    "        }, \n",
    "        'q0': {\n",
    "            '': {\n",
    "                '$': {('q_accept', ('', '$'))}, \n",
    "                 'S': {('q1', 'b'), ('q0', 'b'), ('q_accept', '')}, \n",
    "                 'T': {('q0', ''), ('q3', 'a')},\n",
    "                'Z':{('q_accept', '$')}\n",
    "            }, \n",
    "            'a': {\n",
    "                'a': {('q0', '')},\n",
    "                'b': {('q_accept', '')}\n",
    "                \n",
    "            }, \n",
    "            'b': {\n",
    "                'b': {('q0', '')}\n",
    "            }\n",
    "        }, \n",
    "        'q1': {\n",
    "            '': {\n",
    "                'b': {('q2', ('T', 'b'))}\n",
    "            }\n",
    "        }, \n",
    "        'q2': {\n",
    "            '': {\n",
    "                'T': {('q0', ('a', 'T'))}\n",
    "            }\n",
    "        }, \n",
    "        'q3': {\n",
    "            '': {'a': {('q0', ('T', 'a'))}}\n",
    "        }\n",
    "    },\n",
    "    initial_state='q_start',\n",
    "    initial_stack_symbol='$',\n",
    "    final_states={'q_accept'},\n",
    "    acceptance_mode='final_state'\n",
    ")\n",
    "test_g_npda.read_input('Xa') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "I will be looking at the (former) statsitical-translation machine Google Translate. SMT generates translations based on statistical models, whose parameters are derived from bilingual text corpora. Thus, SMT is a fully supervised process. The corpora (just large bodies of text) are all preselected, manipulated, and prepared \"by hand,\" (likely aided by some well-defined functions), usually extracted from large international organizations such as the EU, UN, World Bank etc. that often have build massive multilingual documents. Since these were originally human translated and edited for legal/political purposes, they serve as a pretty accurate source of pre-classified data. As for how the model is actually constructed, phrases, of length to five (usually done through a process of ngrams, so if ngrams=3, every series of three words), are assessed based on their frequency of occuring in a document. The statistical model says more or something something along the lines of \"which foreign sentence, 'f', produces its english translation \"e.\" In other words, what is the probability of e given f, P(e|f). The statistical model allows us to infer if there's any relationship among phrases words in between the two languages\n",
    "\n",
    "Rule-based translations relies on many many built-in linguistic and grammatical rules, and even more bilingual dictionaries. This in effect tells us how a word or phrase in the source language should be read in another language. RBMT is based on morphological, syntactic, and semantic factors, working better, or even requiring, a near-full set of dictionary translations. Can only do what it is told to do. I would argue SMT ought to be preferred over RBMT. They're built on phrase-based systems, offering more fluid and \"better\" translations. This is also in part due to the fact that they're trained on human work, how humans actually use their respective languages. Lastly, statistical modeling is far more flexible than rule-based approaches, they adopt a bottom-up approach whereas rule-based is very top down. There's no need for a team of linguistic specialists to seminate their expertise on sentence structures, but instead, we generate predictions that two phrases are indeed related based on a probalistically acceptable threshold. I'd imagine that rule-based machines would require a context-free language generator/recognizer. They're not able to recognize anything outside of the basic unit of words; so the rules they recognize are likely context free. SMT on the other hand probably requires context-sensitive languages. If I see the word \"water,\" I can't just translate the english noun to its french equivalent \"eau,\" but instead, based on its context, it could follow a subjective noun, making it a verb. If this were the case, the more appropriate translation would be \"arroser,\" meaning \"to water.\" Furhtermore, if the subjective pronoun was \"I water,\" the correct translation and conjugation should instead be \"arrose.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5: HC tags\n",
    "\n",
    "#probability - Question 4 asked us to dive into the world of statistical machine tranlsations. Although not given the oppurtunity to create any probability models ourselves, in this question I apply knowledge and understanding of SMT's, which themselves are applications of conditional probability. The summary is clear, concise, and ultimately gets at the heart of what is going on with these technologies and algorithms. Furthermore, the benefits to using statistical models in ML/NLP are highlighted, and the larger picture view of how probability can be used for prediction/classification ML problems is provided.\n",
    "\n",
    "#heuristics - similar to the previous assignment, I tried really hard to apply this HC to make my own life easier. A simple heuristic was employed so as to save time with the general task. The intuition was to abstract away repetitive tasks with other code functions. While last time I used this heuristic of \"abstract when possible\" was to save time typing, this time I realized I could use it for a practical implementation of Sisper's CFG to PDA method. Similarly, I recognized the repetitive nature of the algorithm that justifies the use of this heuristic, since code is optimized for looping tasks. There was also another pratical consideration. I tried to draw the PDA by hand, and upon each mistake, I more or less had to restart, rename all the states etc. so as to make the final work not to messy. By abstracting away the need for manual re-edits, code made sense as well. I wasn't declaring all the states individually, but instead iteratively, meaning the states and transitions would be generated in a systematic way. In the code, I also abstract away needing to type all variables/terminals.  Most importantly, I abstracted away the need to type the hundreds of transitions myself. This was the most important. All of the transitions in Sisper's PDA follow general patterns, and they exist based on their structure in the rules. Thus, code could be used instead to suplement the process. The success of the algorithm is a testament to the application of heuristics  \n",
    "\n",
    "#levelsofanalysis - I'm a bit surprised myself that I used this HC, but it was all thanks to one bug, for which I stayed up to sunrise (literally) trying to solve. Looking back, the bug was such a minute typo its laughable, but either way, without levels of analysis, I would have never been able to resolve it. Here is the bug:\n",
    "\n",
    "```\n",
    "def cfg_to_npda_helper(grammar):\n",
    "    transitions = {\n",
    "        'q_start': {\n",
    "            '': {\n",
    "                '$': {('q_0', ('S', '$'))},\n",
    "            },\n",
    "            'X': {'$':{('q_start', ('Z', '$'))}}\n",
    "        },\n",
    "        'q0': {\n",
    "            '': {\n",
    "                '$':{('q_accept', '$')}\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "```   \n",
    "\n",
    "No matter what I did, I could not find out why my NPDA was not accepting what it should be accepting. The first level where the problem might arise is conceptually: perhaps Sisper got it wrong. But then I thought, \"the guy's pretty smart, he probably knows what he's talking about, and this is his book's 3rd edition if something wrong still went unchecked that would be surprising,\" and wanted to dismiss the possibility, but nonetheless I verified that transitions outputted should have accepted my test string, and it was fine. If the issue wasn't with Sisper's methodology in generating the transitions, then perhaps the error lies at the dependency level. If I used automata-lib's syntax wrong, or the data structure of transitions were off, then perhaps what the transitions weren't transitioning how they're supposed to. This too I double-checked, and even built a test NPDA and everything worked there. This suggested my analysis had to go to deeper layer still. I peeled back each loop of the function to make sure it looked ok, and it did. This then meant that the only remaining level of my code to check is the hard-code. This refers to the initial variables I set in the beginning. These levels although usually easily noticeable when flawed, are particularly dangerous because of how they impact/interact with the other levels of the function. They often get called upon, define higher levels, and initializes the functionality of the other levels. That last part I realized I did not check: perhaps my initialization was wrong which created a ripple effect through the other layers of the code, causing it all to not even really run in the first place. Surely enough, as you can see above, I label 'q_0' instead of 'q0.' Meaning even with all the other levels being accurate in principle, they were running on a state that never existed. It was a rather costly typo, several hours of work in fact, but by finallt resorting to levels of analysis in a novel way, with my function itself, and understanding how the different levels interact with one another, the diagnosed problem was finally resolved."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
